---
title: "The effect of stimuli on the neuronal activity in the mice's visual cortex: Final Project STA 207"
author: "Sirapat Watakajaturaphon"
date: "March 19, 2023"
output:
  html_document:
    df_print: paged
    number_sections: yes
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

***

You can find the R codes at the Code Appendix section.

# Abstract 
In this project, we use the dataset from the study conducted by Steinmetz et al. (2019) to study the effect of the two visual stimuli on the activity of neurons in the mice's visual cortex. The neuronal activity was recorded during individual trials in the form of spike trains. Using a mixed-effect analysis of variance (ANOVA) model, we found that the visual stimuli have a significant interaction effect on the neuronal responses. Using this finding, we can build a predictive model for the outcome of each trial with high prediction performance.


# Introduction
Steinmetz et al. (2019) [1] conducted experiments on ten mice over 39 sessions to investigate their neuronal activity when performing a visual discrimination task. The visual stimuli in the study were randomly presented on two screens, placed on left and right sides of the mouse, with different contrast levels. The mice were rewarded if they could correctly indicate which of the two stimuli had higher contrast, by turning a wheel controlled by their forepaws.

The dataset used in this project will be a subset of data collected by Steinmetz et al., as we only focus on five sessions (Sessions 1 to 5) assigned to two mice Cori and Frossman. The methods used in this project are an analysis of variance (ANOVA) model with mixed effect for inferential analysis and a generalized linear model for predictive modeling. We aim to study the effect of the two visual stimuli on the neuronal responses in the visual cortex of those two mice. To be specific, we would like to examine whether such effect is additive or the interaction effect of the left and right stimuli is present. We will then use this information to build a predictive model for mice action in individual trials.


# Background 
The dataset contain the records from five sessions. Sessions 1 to 3 were assigned to the mouse Cori, and Sessions 4 to 5 were to the mouse Frossman. Each session is divided into several hundred trials. In each trial, the left and right visual stimuli were randomly presented to Cori and Frossman on the screens. The mice were then asked to make decisions based on the contrast level of each visual stimulus. They were rewarded if they turned a wheel to indicate which of the two stimuli had higher contrast, or if they did not turn a wheel when no stimulus was presented. The mice was rewarded with equal chance for either a left or right choice, when stimuli had an equal contrast level.

The activity of the neurons in the mice’s visual cortex during the trials was represented by spike trains within the analysis window, from the onset of the stimuli to 0.4 seconds post-onset. The spike trains are collections of timestamps corresponding to neuron firing. The mice were allowed to turn a wheel immediately after the stimuli were displayed. If they did not turn a wheel within a 1.5 second time frame after stimulus onset, we say that the mice made no movement.

For each trial, the key five variables are defined as follows. 

- `feedback_type` type of the feedback with two levels: 1 for success and -1 for failure
- `contrast_left` contrast level of the left stimulus with four levels: 0, 0.25, 0.5, and 1
- `contrast_right` contrast level of the right stimulus with four levels: 0, 0.25, 0.5, and 1
- `time` centers of the time bins for `spks`  
- `spks` numbers of spikes of neurons in the visual cortex in time bins defined in `time`

Note that the contrast level 0 indicates the absence of a stimulus. 

In our analysis, each trial is treated as the basic unit. However, from Table 1, we can see that the variable `spks` is a collection of many data points. We need to choose one summary measure (for example, mean number of spikes across all neurons) to represent `spks` for each trial. For more details, see Section 4.


# Descriptive analysis 
From Table 1, we can see that 

- the numbers of trials in each session are different.  
- the numbers of neurons in each session are different, for example, there are 178 neurons in each trial in Session 1 but 533 neurons in Session 2. 

```{r}
library(kableExtra)
df = data.frame(C1 = c('Session1','Session2','Session3','Session4','Session5'),
                C2 = c('214','251','228','249','254'),
                C3 = c('178 x 39','533 x 39','228 x 39','120 x 39','99 x 39'))
kbl(df, align = "c", col.names =c('Sessions','Number of Trials in each session','Neurons x Timestamps'), 
    caption='Table 1: Format of the original dataset') %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>%
  add_header_above(c(" ", "" , "Dimension of Spikes in each trial, or the collection of" = 1))
```

To obtain one summary measure for the spike trains (within a given 0.4 seconds time interval) with a trial treated as the basic unit, we define the mean firing rate. The mean firing rate is defined as, for each trial, the average number of spikes per second across all neurons within a given 0.4 seconds time interval. It is calculated as, e.g. for the first trial of Session 1, we compute the summation of `spks` and then divided by $t=0.4$ to get the firing rate (per second) and then finally divided by the number of neurons $178$ to get the mean firing rate. It is an appropriate variable for each basic unit, as it also captures some information about the neural responses. Moreover, by computing the mean values of firing rate of the neurons, we make them sufficiently comparable across trials and sessions.

Hence, now the key variables in our study are:

- `mean_firingrate` the average number of spikes per second across all neurons within a given 0.4 seconds time interval.
- `sessions` Sessions 1 to 5 
- `contrast_left` we refer to it as left contrast.
- `contrast_right` we refer to it as right contrast. 
- `feedback_type` 

Here is what the first five rows of the dataset look like:

```{r, results='hide'} 

session=list()
for(i in 1:5){
  session[[i]]=readRDS(paste('./Data/session',i,'.rds',sep='')) }

t = 0.4 # analysis window

n.trial1 = length(session[[1]]$spks)
n.trial2 = length(session[[2]]$spks)
n.trial3 = length(session[[3]]$spks)
n.trial4 = length(session[[4]]$spks)
n.trial5 = length(session[[5]]$spks)

n.neuron1 = dim(session[[1]]$spks[[1]])[1]
n.neuron2 = dim(session[[2]]$spks[[1]])[1]
n.neuron3 = dim(session[[3]]$spks[[1]])[1]
n.neuron4 = dim(session[[4]]$spks[[1]])[1]
n.neuron5 = dim(session[[5]]$spks[[1]])[1]

sessions = c(rep(1, times=n.trial1), rep(2, times=n.trial2), 
         rep(3, times=n.trial3), rep(4, times=n.trial4), rep(5, times=n.trial5))
sessions = as.factor(sessions)
n = length(sessions)

# mean firing rate 
firingrate1 = numeric(n.trial1)
for(i in 1:n.trial1){
  firingrate1[i] = sum(session[[1]]$spks[[i]])/n.neuron1/t }

firingrate2 = numeric(n.trial2)
for(i in 1:n.trial2){
  firingrate2[i] = sum(session[[2]]$spks[[i]])/n.neuron2/t }

firingrate3 = numeric(n.trial3)
for(i in 1:n.trial3){
  firingrate3[i] = sum(session[[3]]$spks[[i]])/n.neuron3/t }

firingrate4 = numeric(n.trial4)
for(i in 1:n.trial4){
  firingrate4[i] = sum(session[[4]]$spks[[i]])/n.neuron4/t }

firingrate5 = numeric(n.trial5)
for(i in 1:n.trial5){
  firingrate5[i] = sum(session[[5]]$spks[[i]])/n.neuron5/t }

mean.firingrate = c(firingrate1, firingrate2, firingrate3, 
                    firingrate4, firingrate5)

contrast.left = numeric(1196)
for (ID in 1:5) {
  n.trials  = length(session[[ID]]$spks)
  n.neurons = dim(session[[ID]]$spks[[1]])[1]
  for(i in 1:n.trials){
  contrast.left[n.trials*(ID-1)+i]=as.numeric(session[[ID]]$contrast_left[i])
  }
}

contrast.left = c(session[[1]]$contrast_left,
                  session[[2]]$contrast_left,
                  session[[3]]$contrast_left,
                  session[[4]]$contrast_left,
                  session[[5]]$contrast_left)
contrast.left = as.factor(contrast.left)
contrast.right = c(session[[1]]$contrast_right,
                   session[[2]]$contrast_right,
                   session[[3]]$contrast_right,
                   session[[4]]$contrast_right,
                   session[[5]]$contrast_right)
contrast.right = as.factor(contrast.right)

feedback = c(session[[1]]$feedback_type, session[[2]]$feedback_type,
             session[[3]]$feedback_type, session[[4]]$feedback_type,
             session[[5]]$feedback_type)
feedback = as.factor(feedback)

mouse.brain = data.frame(mean.firingrate, sessions, contrast.left, contrast.right, feedback)
str(mouse.brain)

```

```{r}
kableExtra::kbl(head(mouse.brain, 5), 
             col.names=c('Mean firing rate', 'Sessions', 'Left contrast', 'Right contrast', 'Feedback type'), 
             caption='Table 2: First five rows of the dataset format we use in the analysis') %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = F)

```

We first see the distribution of each key variable. Since the `mean_firingrate` variable is quantitative, we can calculate its summary statistics shown in Table 3. For the categorical variables, we plot the bar plots in Figure 1. From Plots 1.1 and 1.2, both `contrast_left` and `contrast_right` have the highest count on 0 (the absence of stimulus). The numbers of trials in each session are quite similar, around 200-250, but not exactly the same, see the second column of Table 1 and Plot 1.3. From Plot 1.4, 65.5\% of `feedback_type` are success with 785 counts.


```{r}
collapse_rows_dt = data.frame(c1=c(0.404), c2=c(1.917), c3=c(2.926), c4=c(2.858), c5=c(3.691), c6=c(7.219))
kableExtra::kbl(collapse_rows_dt, align = "c", col.names = c('Min','1 st Quantile','Median','Mean','3rd Quantile','Max'), caption='Table 3: Desciptive statistics for the mean firing rate') %>%
  kable_paper(full_width = F) 

```

```{r,fig.align='center',out.width='70%', fig.cap='Figure 1: Bar plots of categorical variables'}
# univariate descriptive analysis

par(mfrow=c(2,2))
# descriptive stats: contrast.left
barplot(table(mouse.brain$contrast.left), ylab='Counts', xlab='Left contrast',
     main='Plot 1.1: Left contrast')

# descriptive stats: contrast.right
barplot(table(mouse.brain$contrast.right), ylab='Counts', xlab='Right contrast',
     main='Plot 1.2: Right contrast')

# descriptive stats: sessions
barplot(table(mouse.brain$sessions), ylab='Counts', xlab='Session',
     main='Plot 1.3: Session')

# descriptive stats: feedback type
barplot(table(mouse.brain$feedback), ylab='Counts', xlab='Feedback type',
     main='Plot 1.4: Feedback type')

```

Next, we see the relationship among the key variables.

- Based on the side-by-side boxplots in Figure 2, there are differences in the mean firing rate across the sessions. However, the mean firing rate has similar distributions across the contrast levels of the left and right visual stimuli.

- Figure 3 suggests that the interaction effect of left and right stimuli is present.

```{r, message=FALSE, fig.align='center', fig.cap='Figure 2: Boxplots of Mean firing rate vs Session, Left contrast, and Right contrast'}
# multivariate descriptive analysis

library(patchwork)
library(ggplot2)
g1 = ggplot(mouse.brain, aes(mean.firingrate,contrast.left)) + geom_boxplot() + 
  xlab('Mean firing rate') + ylab('Left contrast') +
  labs(title='Plot 2.2: Outcome vs Left contrast')


g2 = ggplot(mouse.brain, aes(mean.firingrate,contrast.right)) + geom_boxplot() + 
  xlab('Mean firing rate') + ylab('Right contrast') +
  labs(title='Plot 2.3: Outcome vs Right contrast')

g3 = ggplot(mouse.brain, aes(mean.firingrate,sessions)) + geom_boxplot() + 
  xlab('Mean firing rate') + ylab('Session') +
  labs(title='Plot 2.1: Outcome vs Session')

(g3 | (g1 / g2)) 

```

```{r, message=FALSE, fig.align='center', fig.cap='Figure 3: Interaction plot of left and right contrast on the response (mean firing rate)',out.width='70%'}
# interaction plot

library(gplots)
with(mouse.brain, interaction.plot(contrast.left, contrast.right, mean.firingrate, 
                            xlab="Left contrast",ylab="Mean firing rate", trace.label='Right contrast'))

```

# Inferential analysis 
From Plot 2.1, we should take sessions into account when studying the mean firing rate. We choose to treat sessions as a random effect because, by doing so, we assume that the effect of sessions on the mean firing rate is drawn from a population of possible sessions, and that the sessions in our dataset are a random sample from that population. This allows us to estimate the variability in the effect of session on the outcome variable, and to incorporate that variability into our model.

The mixed-effects model is written as:

\begin{align*}
Y_{ijkl}=\mu+\eta_k&+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\epsilon_{ijkl},\\
i=&1,2,3,4,\\
j=&1,2,3,4,\\
k=&1,2,3,4,5,\\
l=&1,...,n_{ijk},\\
\eta_k&\overset{{\rm i.i.d}}{\sim}{\rm N}(0,\sigma_\eta^2),\\
\epsilon_{ijkl}&\overset{{\rm i.i.d}}{\sim}{\rm N}(0,\sigma^2)
\end{align*}

where the outcome variable $Y$ is the mean firing rate, $\mu$ is the overall population mean, $\alpha$ is the fixed effect of left contrast, $\beta$ is the fixed effect of right contrast, $(\alpha\beta)$ is the interaction term of left and right contrast, $\eta$ is the random effect of sessions, and $\epsilon$ is the random errors for an individual observation. 

The indexes $i$ and $j$ represent the levels of left contrast and those of right contrast respectively: contrast level of 0 ($i,j=1$), 0.25 ($i,j=2$), 0.5 ($i,j=3$), and 1 ($i,j=4$). The index $k$ represents the level of sessions. 

The AVOVA table is shown in Table 4.

```{r, message=FALSE}
# mixed effect ANOVA model

library(lmerTest)
fit = lmer(mean.firingrate ~ contrast.left * contrast.right + (1 | sessions), data = mouse.brain)
kableExtra::kbl(anova(fit), digits = 3, caption='Table 4: ANOVA table of the mixed effect model')  %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T)

```

From the model summary outputs, we have the estimates of $\sigma_\eta^2=1.27$ (sessions) and $\sigma^2=0.40$ (error terms). Thus, the total variation is 1.67 and then the estimate of the proportion of variability that is due to variability in session is about 76\%.

To answer the question: how do neurons in the visual cortex respond to the stimuli presented on the left and right? We would like to test whether the left and right stimuli have additive effects on the neural responses, i.e., whether their interaction effect exists. The null and alternative hypotheses for this test can be expressed as follows: 
$$
H_0:(\alpha\beta)_{ij}=0\hspace{1mm}\text{for all}\hspace{1mm}i,j\quad{\rm vs}\quad H_1:\text{at least one of }(\alpha\beta)_{ij}\hspace{1mm}\text{is not equal to}\hspace{1mm}0,
$$

which can also be seen as

- The full model: $Y_{ijkl}=\mu+\eta_k+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\epsilon_{ijkl}$; and

- The reduced model: $Y_{ijkl}=\mu+\eta_k+\alpha_i+\beta_j+\epsilon_{ijkl}$.

To investigate whether a full or reduced model is preferred, a likelihood ratio test can be performed by the **anova()** function in R. Since the output p-value in Table 5 is calculated to be 0.04, the full model is preferred, indicating that the interaction effect is present at the significance level 0.05.

```{r, message=FALSE}
# test for interactions

full.model = fit
reduced.model = lmer(mean.firingrate ~ contrast.left + contrast.right + (1 | sessions), 
                     data = mouse.brain)
options(knitr.kable.NA = '')
kableExtra::kbl(anova(reduced.model, full.model), caption='Table 5: The output of a likelihood ratio test for interaction effect') %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T)

```

# Model diagnosis and sensitivity analysis
We need to check the model assumptions.

- Plot the Pearson residuals verses the fitted values using the **plot()** function in R, see Figure 4. The points randomly scatter around the horizontal zero line. However, the spread appears to be slightly increasing as the fitted values increase. Hence, the linearity assumption seems to be satisfied but the constant variance seems to be violated.

```{r, fig.align='center', out.width='70%', fig.cap='Figure 4: Pearson residuals vs fitted plot'}
# Pearson residual plot

plot(fit, ylab='Pearson residuals', xlab='Fitted values')

```

- Plot Figure 5 to check the normality of the random effect and the residuals. Two Q-Q plots show a straight line pattern, so both the random effect of sessions and the residuals seem to have a normal distribution.

```{r, fig.align='center', out.width='70%', fig.cap='Figure 5: Q-Q plots of the random effects of sessions and the residuals'}
# QQ plots 

par(mfrow = c(1,2))
qqnorm(ranef(fit)$sessions[,"(Intercept)"], main = "Random effects of sessions")
qqline(ranef(fit)$sessions[,"(Intercept)"], col=2, lty=2)

qqnorm(resid(fit), main = "Residuals")
qqline(resid(fit), col=2, lty=2)

```

When including the random effect of some variable, it is always necessary to check whether such random effect actually exists. The hypotheses of the test for the random effect of sessions are:
$$
H_0:\sigma^2_\eta=0\quad{\rm vs}\quad H_1:\sigma_\eta^2\neq0.
$$
Again, we use a likelihood ratio test since the sample size is large enough. Since the resulting p-value in Table 6 is very small, we indeed need to account for the random effect from sessions.

```{r,message=FALSE}
# a purely fixed effects model

reduced.model = lm(mean.firingrate ~ contrast.left * contrast.right + 1, 
                   data = mouse.brain)
kableExtra::kbl(anova(full.model, reduced.model), caption='Table 6: the output of a likelihood ratio test for random effects of sessions') %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T)

```

Therefore, we can conclude that our mixed-effects ANOVA model is appropriate. Even though there is some unequal variance issue, it is not very severe.

# Predictive modeling
Here, we want to predict the outcome of each trial using the neuronal activities and stimuli. Since the outcome `feedback_type` is binary, a logistic regression model is one of many useful tools to build a predictive model. According to Section 4, we know that the left and right stimuli have additive effects on the neuronal responses. Hence, if we want to use the variables `contrast_left` and `contrast_right`, we may need to include their interaction term `contrast_left:contrast_right` as well. Moreover, the random effect are necessarily to be included for each session to account for the differences among sessions.

We will split the whole dataset into a test set (the first 100 trials in Session 1) and a training set (the remaining trials), in order to avoid an overfitting that may happen from using the same dataset in both model training and testing steps. 

Using a training set, we fit a logistic regression model with mixed effects using the **glmer()** function in R. The predictor variables in our predictive model are: `contrast_left` (fixed effect), `contrast_right` (fixed), the interaction effect  `contrast_left:contrast_right` (fixed), and `sessions` (random). Then we evaluate the prediction performance on the test set, using the following criteria.

1. Sensitivity: The probability of fail outcome correctly identified as failure is equal to $6/26\approx23\%$ based on Table 7;

2. Specificity: The probability of successful outcome correctly identified as success is equal to $48/74\approx65\%$ based on Table 7.

```{r,results='hide',message=FALSE}

# Split data set
train = mouse.brain[-(1:100),]
test  = mouse.brain[1:100,]

# GLM 
fit.train2 = glmer(feedback ~ contrast.left * contrast.right + (1|sessions), 
                family=binomial, data = train)

threshold = 0.5
predicted_values = ifelse(predict(fit.train2, newdata = test)>threshold,1,-1)
actual_values = test$feedback
conf_matrix = table(predicted_values, actual_values)
conf_matrix

```

```{r}
df = data.frame(C1 = c('failure','success'),
                C2 = c('6','20'),
                C3 = c('26','48'))
kbl(df, align = "c", col.names =c('Predicted feedback type','failure','success'), caption='Table 7: Confusion matrix of predictive model using stimuli and random effect of each session') %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>%
  add_header_above(c(" ", "Actual feedback type" = 2))

```

Here, we fit a logistic regression model with predictors `mean_firingrate` (fixed effect), `contrast_left` (fixed), `contrast_right` (fixed), the interaction effect `contrast_left:contrast_right` (fixed), and `sessions` (random). The prediction performance of the second model would be:

1. Sensitivity is equal to $8/26\approx31\%$ based on Table 8;

2. Specificity is equal to $63/74\approx85\%$ based on Table 8.

```{r,message=FALSE,results='hide'}
fit.train1 = glmer(feedback ~ contrast.left * contrast.right + (1|sessions) + mean.firingrate, 
                family=binomial, data = train)
summary(fit.train1)

predicted_values = ifelse(predict(fit.train1, newdata = test)>threshold,1,-1)
actual_values = test$feedback
conf_matrix = table(predicted_values, actual_values)
conf_matrix

```

```{r}
df = data.frame(C1 = c('failure','success'),
                C2 = c('8','18'),
                C3 = c('11','63'))
kbl(df, align = "c", col.names =c('Predicted feedback type','failure','success'), 
    caption='Table 8: Confusion matrix of predictive model using neuronal activity, stimuli, and random effect of each session') %>%
  kable_paper(full_width = F) %>%
  column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>%
  add_header_above(c(" ", "Actual feedback type" = 2))
```

Comparing both predictive models, we can see that the second model has the best prediction performance.

# Discussion and conclusions
Our primary goal in this study is to understand the relationship between the outcome (the activity of the neurons in the mice’s visual cortex) and the two stimuli where each trial is treated as the basic unit. The neuronal activity was expressed in the form of spike trains, which are collections of timestamps and neuron firing, within the analysis time window. We need to find a summary measure to represent each collection. In this project, we use the mean firing rate, the average number of spikes per second across all neurons within a given 0.4 seconds time interval, as the outcome variable $Y$. 

The mice Cori and Frossman were assigned to five sessions. Thus, we expect to see some differences in the outcome across the sessions. The differences among the sessions are taken into account in the form of the random effect. Therefore, our ANOVA model has mixed effects $Y_{ijkl}=\mu+\eta_k+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\epsilon_{ijkl}$ where $\alpha,\beta,(\alpha\beta)$ are the fixed effects of visual stimuli and $\eta$ is the random effect of each session. Based on the output from a likelihood ratio test for interactions, the interaction effect $(\alpha\beta)$ between left stimulus $\alpha$ and right stimulus $\beta$ are indeed significant. According to model diagnosis in Section 6, the model follows most model assumptions with the exception of equal variance assumption, so the inference results are sufficiently reliable. The problem might occur because, as we already observed from Table 1 in Section 4, the numbers of trials and numbers of neurons vary across the sessions. For future work, we can improve the data analysis even further. For instance, instead of using the mean firing rate, we may employ the clustering method to group spike trains corresponding to neurons with common features. 

Using the findings that the interaction effect of two stimuli and the random effect of sessions are significant, we can build a well-preformed predictive model. A logistic regression model with predictors including the neuronal activity, stimuli, and random effect of each session, has the best prediction performance in terms of sensitivity (the probability of fail feedback type correctly identified as failure: 31\%) and specificity (the probability of successful feedback type correctly identified as success: 85\%).


# Acknowledgement {-}
I am grateful to all of those with whom I have discussed this project, Matthew Chen and Jasper Tsai. 

# Reference {-}
[1] Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266–273 (2019). https://doi.org/10.1038/s41586-019-1787-x

[2] Random and mixed effects ANOVA model. https://stat.ethz.ch/~meier/teaching/anova/random-and-mixed-effects-models.html#eq:cell-means-random. Accessed March 19, 2023.

[3] Split-plot design. https://stat.ethz.ch/~meier/teaching/anova/split-plot-designs.html#tab:oats-design. Accessed March 19, 2023.

[4] Diagnosis for mixed models. https://www.ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer.html. Accessed March 18, 2023.


# Code Appendix {-}

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```

# Session info {-}

```{r}
sessionInfo()
```
